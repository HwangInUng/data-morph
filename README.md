# data-morph
## ğŸš€ Overview
> DataMorphëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ íƒ€ê²Ÿ ê°„ì˜ ììœ ë¡œìš´ ë³€í™˜ì„ ì§€ì›í•˜ëŠ” ê²½ëŸ‰ Java ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì§ê´€ì ì¸ Fluent APIë¡œ íŒŒì¼, ê°ì²´, ë©”ëª¨ë¦¬ ë°ì´í„°ë¥¼ ì›í•˜ëŠ” í˜•íƒœë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Key Features
- Flexible I/O : File <-> File, Object <-> File, Memory Processing ì§€ì›
- Fluent API : ì§ê´€ì ì¸ ë©”ì„œë“œ ì²´ì´ë‹ìœ¼ë¡œ ì½ê¸° ì‰¬ìš´ ì½”ë“œ
- High Performance : ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ë° ë©”ëª¨ë¦¬ ìµœì í™”
- Zero Dependencies : ìˆœìˆ˜ Java êµ¬í˜„ìœ¼ë¡œ ê°€ë²¼ìš´ ìš©ëŸ‰
- Configuration-Driven : YAML ë“± ì„¤ì • íŒŒì¼ ì§€ì›

### Why DataMorph?
|DataMorph|vs. Jackson + Commons CSV|
|---|---|
|í†µí•©ëœ ë‹¨ì¼ API|ì—¬ëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¡°í•© í•„ìš”|
|Zero Dependencies|Multi Dependencies|
|ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥|ë³µì¡í•œ ì„¤ì •|

### Data Flow Architecture
```mermaid
flowchart LR
    subgraph "Input Sources"
        A1[Files<br/>CSV, JSON, XML]
        A2[Objects<br/>List, Array]
        A3[Strings<br/>Raw Data]
        A4[Streams<br/>InputStream]
    end
    
    subgraph "Processing Pipeline"
        B1[Parser<br/>Format Detection]
        B2[Transform Engine<br/>â€¢ Rename Fields<br/>â€¢ Convert Types<br/>â€¢ Calculate Values<br/>â€¢ Add/Remove Fields]
        B3[Filter Engine<br/>â€¢ Conditions<br/>â€¢ Validation<br/>â€¢ Range Check<br/>â€¢ Pattern Match]
        B4[Memory Manager<br/>â€¢ Batch Processing<br/>â€¢ Backpressure Control<br/>â€¢ GC Optimization]
    end
    
    subgraph "Output Targets"
        C1[Files<br/>Any Format]
        C2[Objects<br/>POJOs, Collections]
        C3[Streams<br/>Reactive Processing]
        C4[Strings<br/>Serialized Data]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    A4 --> B1
    
    B1 --> B2
    B2 --> B3
    B3 --> B4
    
    B4 --> C1
    B4 --> C2
    B4 --> C3
    B4 --> C4
    
    B4 -.->|"Memory Monitoring"| B2
    B4 -.->|"Batch Size Control"| B3
    
    style B2 fill:#06923E
    style B3 fill:#E67514
    style B4 fill:#9B177E
```

### Core Components
```mermaid
classDiagram
    class DataMorph {
        +from(source) DataSource
        +fromString(content) DataSource
    }
    
    class DataSource {
        +transform(mapping) DataSource
        +filter(condition) DataSource
        +validate(rules) DataSource
        +batchSize(size) DataSource
        +to(target) ProcessResult
        +toList() List~DataRow~
        +toStream() Stream~DataRow~
        +toStreamingTarget(handler) ProcessResult
    }
    
    class StreamingProcessor {
        +processBatch(batch) void
        +handleBackpressure() void
        +getMemoryUsage() long
        +adjustBatchSize() void
    }
    
    class FieldMapping {
        +rename(old, new) FieldMapping
        +convert(field, type) FieldMapping
        +add(field, function) FieldMapping
        +remove(field) FieldMapping
    }
    
    class ValidationRules {
        +required(fields...) ValidationRules
        +range(field, min, max) ValidationRules
        +pattern(field, regex) ValidationRules
    }
    
    class MemoryManager {
        +monitorUsage() long
        +triggerGC() void
        +optimizeBatchSize(usage) int
    }
    
    class ErrorHandler {
        +skipErrors(boolean) ErrorHandler
        +collectErrors() List~ProcessingError~
        +onError(handler) ErrorHandler
    }
    
    DataMorph --> DataSource
    DataSource --> StreamingProcessor
    DataSource --> FieldMapping
    DataSource --> ValidationRules
    DataSource --> MemoryManager
    DataSource --> ErrorHandler
    StreamingProcessor --> MemoryManager
```

### Package Structure
```bash
com.datamorph/
â”œâ”€â”€ core/                           # í•µì‹¬ API ë° ë°ì´í„° ëª¨ë¸
â”œâ”€â”€ parser/                         # íŒŒì¼ íŒŒì‹± ì—”ì§„
â”œâ”€â”€ transform/                      # ë°ì´í„° ë³€í™˜ ì—”ì§„
â”œâ”€â”€ writer/                         # íŒŒì¼ ì¶œë ¥ ì—”ì§„
â”œâ”€â”€ streaming/                      # ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ë° ìµœì í™”
â”œâ”€â”€ Config/                         # ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ error/                          # ì˜ˆì™¸ ì²˜ë¦¬
â””â”€â”€ util/                           # ìœ í‹¸ë¦¬í‹°
```
---

## ğŸ’» Contents
### âš¡ï¸ Quick Start - (ì‘ì—… ì¤‘)
#### Maven
```xml
<dependency>
    <groupId>com.example</groupId>
    <artifactId>datamorph</artifactId>
    <version>1.0.0</version>
</dependency>
```

#### Gradle
```gradle
implementation 'com.example:datamorph:1.0.0'
```

#### Basic File Processing
```java
// file data read
DataSource dataSource = DataMorph.from("employees.csv");

// filter & transform
List<DataRow> results = dataSource
    .filter(row -> {
        Integer age = row.getInt("age");
        return age != null && age >= 30;
    })
    .transform(row -> {
        Integer salary = row.getInt("salary");
        if (salary != null) {
            int bonusSalary = (int)(salary * 1.1);
            row.set("salary", bonusSalary);
        }
    })
    .toList();
```

#### String Content Processing
```java
// JSON data read
String jsonData = "[{\"name\":\"John\",\"age\":30}]";
DataSource dataSource = DataMorph.fromString(jsonData, Format.JSON);

// data process
List<DataRow> results = dataSource.toList();
```

#### CSV File Example
```java
// CSV: name,age,department
// John,30,Engineering
// Jane,25,Marketing

DataSource employees = DataMorph.from("employees.csv");

List<DataRow> seniorEngineers = employees
    .filter(row -> "Engineering".equals(row.getString("department")))
    .filter(row -> row.getInt("age") > 30)
    .toList();
```

### ğŸ“š API Examples

#### íŒŒì¼ ì²˜ë¦¬
```java
// CSV file read
DataSource csvData = DataMorph.from("data.csv");

// JSON file read 
DataSource jsonData = DataMorph.from("data.json");

// auto formatting
DataSource autoData = DataMorph.from("unknown.csv");
```

#### ë¬¸ìì—´ ì²˜ë¦¬
```java
// CSV parsing
String csvContent = "name,age\nJohn,30\nJane,25";
DataSource csvData = DataMorph.fromString(csvContent, Format.CSV);

// JSON parsing
String jsonContent = "[{\"name\":\"John\",\"age\":30}]";
DataSource jsonData = DataMorph.fromString(jsonContent, Format.JSON);
```

#### ë°ì´í„° ë³€í™˜
```java
DataSource transformed = DataMorph.from("employees.csv")
    .transform(row -> {
        Integer age = row.getInt("age");
        if (age != null) {
            String ageGroup = age < 30 ? "ì Šì€ì¸µ" : age < 50 ? "ì¤‘ë…„ì¸µ" : "ì¥ë…„ì¸µ";
            row.set("age_group", ageGroup);
        }
    })
    .transform(row -> row.set("salary", (int)(salary * 1.05)));
```

#### ë°ì´í„° í•„í„°ë§
```java
DataSource filtered = DataMorph.from("sales.csv")
    .filter(row -> row.isOverCount())
    .filter(row -> "ì„œìš¸".equals(row.getString("region")));
```

#### ì²´ì¸ ë°©ì‹ ì²˜ë¦¬
```java
List<DataRow> result = DataMorph.from("customers.csv")
    .filter(row -> "VIP".equals(row.getString("grade")))
    .transform(row -> row.set("discount", "20%"))
    .filter(row -> "Active".equals(row.getString("status")))
    .toList();
```

#### ì—ëŸ¬ ì²˜ë¦¬
```java
try {
    DataSource data = DataMorph.from("data.csv");
    List<DataRow> results = data.toList();
} catch (IllegalArgumentException e) {
    // íŒŒì¼ ê´€ë ¨ ì˜¤ë¥˜ (ì¡´ì¬í•˜ì§€ ì•ŠìŒ, ì˜ëª»ëœ ê²½ë¡œ ë“±)
    System.err.println("íŒŒì¼ ì˜¤ë¥˜: " + e.getMessage());
} catch (ParseException e) {
    // íŒŒì‹± ì˜¤ë¥˜ (ì˜ëª»ëœ í˜•ì‹, ì§€ì›í•˜ì§€ ì•ŠëŠ” í¬ë§· ë“±)
    System.err.println("íŒŒì‹± ì˜¤ë¥˜: " + e.getMessage());
}
```

### ğŸ“„ Documentation - (ì‘ì—… ì¤‘)
ìì„¸í•œ API ì‚¬ìš©ë²•, ê°•í™”ëœ ê¸°ëŠ¥ê³¼ ì„¤ì • ì˜µì…˜ë“¤ì€ ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì„¸ìš”.
- [API Reference Guide]() - ì „ì²´ ë©”ì„œë“œ ë¬¸ì„œí™” ë° ì˜ˆì œ
- [Configuration Guide]() - YAML ë“± ì„¤ì • ë° ê³ ê¸‰ ì˜µì…˜
- [Performance Tuning]() - ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ë° ìµœì í™”
- [Example]() - ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ ë° ìƒ˜í”Œ

### âš™ï¸ Configuration - (ì‘ì—… ì¤‘)
#### YAML Configuration
#### Properties Configuration
#### Using Configuration

### ğŸ¯ Performance Benchmarks - (ì‘ì—… ì¤‘)
#### Processing Performance
|File Size|Records|Processing Time|Memory Usage|Throughput|
|---|---|---|---|---|
|10MB|||||
|100MB|||||
|1GB|||||

#### Memory Efficiency
|Operation Type|File Size|Peak Memory|Average Memory|Memory Growth|
|---|---|---|---|---|
|Simple Transform|||||
|Complex Transform|||||
|Streaming Process|||||
|Batch Process|||||

#### Feature Performance
|Feature|Small Files(<10MB)|Large Files(1GB+)|Notes|
|---|---|---|---|
|CSV Parsing||||
|JSON Generation||||
|Field Transformation||||
|Data Validation||||
|Error Recovery||||

#### Streaming vs Non-Streaming
|File Size|Non-Streaming Memory|Streaming Memory|Memory Reduction|
|---|---|---|---|
|100MB||||
|1GB||||
|5GB||||

---

## ğŸªª ë¼ì´ì„ ìŠ¤ í‘œê¸° - (ì‘ì—… ì¤‘)
